{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda19887",
   "metadata": {},
   "source": [
    "# 运动边界非定常流场预测\n",
    "\n",
    "\n",
    "需要安装 **MindFlow >=0.1.0** 版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4216556",
   "metadata": {},
   "outputs": [],
   "source": [
    "mindflow_version = \"0.1.0\"  \n",
    "!pip uninstall -y mindflow-ascend\n",
    "!pip install mindflow-ascend==$mindflow_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b427c68",
   "metadata": {},
   "source": [
    "## 概述\n",
    "\n",
    "CFD作为一种通过数值方法来模拟和解析流体运动的重要工具，极大便利了流体力学相关问题的科学研究，在设计、优化和研究领域提供准确的数据和见解并发挥着重要作用。流体力学中具有代表性和研究价值的一类问题是：对具有移动边界的非定常流场系统进行模拟，以分析运动结构在流场中的受力情况，可在工程上优化设计运动结构，为航空航天飞行器以及航海器等外形优化提供方案策略。高精确度计算流体力学技术（CFD）能够准确模拟流场演化和结构受力情况，但是高精度动边界问题需要大量网格，导致硬件消耗和计算时间成本巨大，另外对动态网格的构造也格外耗时。\n",
    "\n",
    "面对CFD在应用于复杂问题时计算量巨大并且计算精度有待提高等问题，智能流体力学领域给出了行之有效的解决方案，深度学习可以通过深度神经网络可学习流动工况与流场之间的演化关系，快速实现流场高精度预测与重构。为了高效解决动边界流场重构问题，提出了一种混合深度神经网络(HDNN)，以实现非定常动边界流场重构，并基于此实现流场快速预测。\n",
    "\n",
    "## 问题描述\n",
    "\n",
    "流场相关尺寸如图所示，其中 $Y = Asin(2πft)$ 代表圆柱体在竖直方向做简谐运动的运动表达式，A为振幅，f为频率；D代表圆柱体直径；矩形边界代表计算域。均匀来流流过运动圆柱体时，在流体与固体相互作用的影响下，会在圆柱体后方形成一系列复杂的流动现象，如边界层分离、交替出现的卡门涡街等，并演化为物理量随时间周期性变化的非均匀流场。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39552eaf",
   "metadata": {},
   "source": [
    "## 模型架构\n",
    "\n",
    "HDNN的基本框架由卷积神经网络（CNN）、卷积长短期记忆网络（ConvLSTM）和反卷积神经网络（DeCNN）组成。使用CNN结构实现特征提取；ConvLSTM学习低维时空特征并进行预测；最后，DeCNN实现预测流场的重建\n",
    "\n",
    "+ 输入层：输入历史流场\n",
    "+ 卷积层：通过多层CNN对输入流场进行降维，提取时空流动特征\n",
    "+ 记忆层：通过ConvLSTM学习低维空间流场时空特征的演变，预测下一时刻\n",
    "+ DeCNN输出层：将预测流场的低维特征恢复到高维空间，通过多层DeCNN重构下一时刻的瞬态流场，并输出预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d5c41",
   "metadata": {},
   "source": [
    "![HDNN.jpg](./images/HDNN.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f317de2",
   "metadata": {},
   "source": [
    "## 训练数据集\n",
    "\n",
    "数据集由非定常二维圆柱绕流的数值仿真流场数据构建的多维矩阵流场快照矩阵构建而成\n",
    "\n",
    "+ 二维圆柱在均匀来流流场中做一维简谐振动，振动频率f（Hz）分别为1.25、1.43、1.67、2.00，振幅比A/D分别为0.5、0.6、0.7、0.8。两两组合总共16组运动状态\n",
    "+ 数据集为某一状态（f,A/D）下的非定常流场序列数据\n",
    "+ 每张流场快照包含3个通道，代表流场的压强分布信息、水平速度信息、竖直速度信息，多维矩阵流场快照矩阵尺寸为：T×C×H×W(C为通道数，H，W分别为snapshot的高和宽）\n",
    "+ 数据集：[下载位置](https://download.mindspore.cn/mindscience/mindflow/dataset/applications/data_driven/move_boundary_hdnn)\n",
    "\n",
    "在这里下载数据可以直接通过运行 python download.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2847f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from mindspore import nn, ops, context, save_checkpoint, set_seed, data_sink, jit\n",
    "from mindflow.utils import load_yaml_config\n",
    "\n",
    "from src import my_train_dataset, AEnet, save_loss_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7406dd",
   "metadata": {},
   "source": [
    "## 训练环境\n",
    "\n",
    "+ 训练采用Mindspore框架的静态图模式（GRAPH）\n",
    "+ 在单卡的Ascend上进行训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5c6d767",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5ca2c",
   "metadata": {},
   "source": [
    "## 训练超参数\n",
    "\n",
    "从config中获得模型、数据、优化器的超参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e3ba84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析命令行参数\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--mode\", type=str, default=\"GRAPH\")\n",
    "parser.add_argument(\"--save_graphs\", type=bool, default=False)\n",
    "parser.add_argument(\"--save_graphs_path\", type=str, default=\"./summary\")\n",
    "parser.add_argument(\"--device_target\", type=str, default=\"Ascend\")\n",
    "parser.add_argument(\"--device_id\", type=int, default=0)\n",
    "parser.add_argument(\"--data_list\", type=list, default=['0.25', '0.30', '0.35', '0.40'])\n",
    "parser.add_argument('--batch_size', type=int, default=16, help=\"batch size\")\n",
    "parser.add_argument(\"--config_file_path\", type=str, default=\"./config.yaml\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "# 设置运行上下文\n",
    "context.set_context(\n",
    "    mode=context.GRAPH_MODE if args.mode.upper().startswith(\"GRAPH\") else context.PYNATIVE_MODE,\n",
    "    save_graphs=args.save_graphs,\n",
    "    save_graphs_path=args.save_graphs_path,\n",
    "    device_target=args.device_target,\n",
    "    device_id=args.device_id\n",
    ")\n",
    "# 判断是否使用 Ascend 设备\n",
    "use_ascend = context.get_context(attr_key='device_target') == \"Ascend\"\n",
    "\n",
    "# 加载配置文件，准备参数\n",
    "config = load_yaml_config(args.config_file_path)  # 从 YAML 配置文件中读取所有设置\n",
    "data_params = config[\"data\"]                      # 数据相关参数字典\n",
    "model_params = config[\"model\"]                    # 模型相关参数字典\n",
    "optimizer_params = config[\"optimizer\"]            # 优化器相关参数字典"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e53d5ec",
   "metadata": {},
   "source": [
    "## 训练过程文件保存路径\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa53aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备保存模型检查点的目录\n",
    "ckpt_dir = optimizer_params[\"ckpt_dir\"]\n",
    "if not os.path.exists(ckpt_dir):                  # 若目录不存在则创建\n",
    "    os.mkdir(ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505908fc",
   "metadata": {},
   "source": [
    "## 构建神经网络及优化器\n",
    "\n",
    "损失函数使用均方误差（Mean Squared Error）损失函数，优化器使用Adam（Adaptive Moment Estimation）优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e0f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建待训练模型\n",
    "model = AEnet(\n",
    "    in_channels=model_params[\"in_channels\"],      # 输入通道数\n",
    "    num_layers=model_params[\"num_layers\"],        # 网络层数\n",
    "    kernel_size=model_params[\"kernel_size\"],      # 卷积核大小\n",
    "    num_convlstm_layers=model_params[\"num_convlstm_layers\"]  # ConvLSTM 层数\n",
    ")\n",
    "# 定义损失函数：均方误差 MSE\n",
    "loss_func = nn.MSELoss()\n",
    "# 定义优化器：Adam\n",
    "optimizer = nn.Adam(\n",
    "    params=model.trainable_params(),               # 可训练参数列表\n",
    "    learning_rate=optimizer_params[\"lr\"]          # 学习率\n",
    ")\n",
    "\n",
    "# 如果使用 Ascend 设备，启用动态损失缩放和自动混合精度\n",
    "if use_ascend:\n",
    "    from mindspore.amp import DynamicLossScaler, auto_mixed_precision, all_finite\n",
    "    loss_scaler = DynamicLossScaler(1024, 2, 100)   # 初始化动态损失缩放器\n",
    "    auto_mixed_precision(model, 'O1')               # 开启 O1 级别混合精度\n",
    "else:\n",
    "    loss_scaler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d32ff9",
   "metadata": {},
   "source": [
    "## 训练框架\n",
    "\n",
    "定义前向传播函数forward_fn，将预测值和真值比较得到损失值loss并返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e34bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前向计算函数，返回损失\n",
    "def forward_fn(inputs, velocity, label):\n",
    "    pred = model(inputs, velocity)                # 前向推理\n",
    "    loss = loss_func(pred, label)                  # 计算 MSE 损失\n",
    "\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.scale(loss)             # 缩放损失\n",
    "    return loss\n",
    "\n",
    "# 计算损失和梯度的函数\n",
    "grad_fn = ops.value_and_grad(\n",
    "    forward_fn, None, optimizer.parameters, has_aux=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faacf783",
   "metadata": {},
   "source": [
    "## 数据集加载\n",
    "\n",
    "给my_train_dataset传参，得到训练数据集和验证数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe1356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备训练和验证数据集\n",
    "dataset_train, dataset_eval = my_train_dataset(\n",
    "    data_params[\"data_dir\"],                     # 数据路径\n",
    "    data_params[\"time_steps\"],                   # 时间步长\n",
    "    args.data_list,                                # 数据列表（如不同参数设置）\n",
    "    batch_size=args.batch_size                     # 批大小\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7331a",
   "metadata": {},
   "source": [
    "## 数据下沉及模型训练\n",
    "\n",
    "定义train_step和eval_step并使用data_sink加速训练，每隔一定训练轮次保存模型文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c63294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义带 @jit 加速的训练步骤函数\n",
    "@jit\n",
    "def train_step(inputs, velocity, label):\n",
    "    loss, grads = grad_fn(inputs, velocity, label)  # 计算损失和梯度\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.unscale(loss)            # 反缩放损失\n",
    "        if all_finite(grads):                        # 若梯度有效，则反缩放梯度\n",
    "            grads = loss_scaler.unscale(grads)\n",
    "    # 应用更新并返回损失\n",
    "    loss = ops.depend(loss, optimizer(grads))\n",
    "    return loss\n",
    "\n",
    "# 定义带 @jit 加速的验证步骤函数，计算并返回 RMSE 损失\n",
    "@jit\n",
    "def eval_step(inputs, velocity, label):\n",
    "    loss = forward_fn(inputs, velocity, label)     # 计算 MSE 损失\n",
    "    loss = ops.sqrt(loss)                          # 转为 RMSE\n",
    "    return loss\n",
    "\n",
    "# 使用数据下沉机制提升性能\n",
    "train_sink_process = data_sink(train_step, dataset_train, sink_size=1)\n",
    "eval_sink_process = data_sink(eval_step, dataset_eval, sink_size=1)\n",
    "train_data_size = dataset_train.get_dataset_size()  # 训练集批数\n",
    "eval_data_size = dataset_eval.get_dataset_size()    # 验证集批数\n",
    "\n",
    "# 用于记录每个 epoch 的平均损失\n",
    "avg_train_losses = []\n",
    "avg_valid_losses = []\n",
    "\n",
    "# 开始循环训练\n",
    "for epoch in range(1, optimizer_params[\"epochs\"] + 1):\n",
    "    train_losses = 0.0\n",
    "    valid_losses = 0.0\n",
    "\n",
    "    # 记录训练开始时间\n",
    "    local_time_beg = time.time()\n",
    "    model.set_train(True)                            # 切换到训练模式\n",
    "\n",
    "    # 遍历所有训练批次\n",
    "    for _ in range(train_data_size):\n",
    "        step_train_loss = ops.squeeze(train_sink_process(), axis=())  # 获取标量损失\n",
    "        step_train_loss = step_train_loss.asnumpy().item()            # 转为 Python 数值\n",
    "        train_losses += step_train_loss\n",
    "\n",
    "    # 计算并记录平均训练损失\n",
    "    train_loss = train_losses / train_data_size\n",
    "    avg_train_losses.append(train_loss)\n",
    "    print(f\"epoch: {epoch}, epoch average train loss: {train_loss:.6f}, \"\n",
    "          f\"epoch time: {(time.time() - local_time_beg):.2f}s\")\n",
    "\n",
    "    # 每隔一定间隔进行验证\n",
    "    if epoch % optimizer_params[\"eval_interval\"] == 0:\n",
    "        eval_time_beg = time.time()\n",
    "        model.set_train(False)                       # 切换到评估模式\n",
    "        for _ in range(eval_data_size):\n",
    "            step_eval_loss = ops.squeeze(eval_sink_process(), axis=())\n",
    "            step_eval_loss = step_eval_loss.asnumpy().item()\n",
    "            valid_losses += step_eval_loss\n",
    "\n",
    "        valid_loss = valid_losses / eval_data_size\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "        print(f\"epoch: {epoch}, epoch average valid loss: {valid_loss:.6f}, \"\n",
    "              f\"epoch time: {(time.time() - eval_time_beg):.2f}s\")\n",
    "\n",
    "    # 每隔一定间隔保存模型\n",
    "    if epoch % optimizer_params[\"save_ckpt_interval\"] == 0:\n",
    "        save_checkpoint(model, f\"{ckpt_dir}/net_{epoch}.ckpt\")\n",
    "\n",
    "# 绘制并保存训练与验证损失曲线\n",
    "save_loss_curve(\n",
    "    avg_train_losses, 'Epoch', 'avg_train_losses', 'Avg_train_losses Curve', 'Avg_train_losses.png'\n",
    ")\n",
    "save_loss_curve(\n",
    "    avg_valid_losses, 'Epoch', 'avg_valid_losses', 'Avg_valid_losses Curve', 'Avg_valid_losses.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1262b22",
   "metadata": {},
   "source": [
    "## 设置训练条件 传参\n",
    "\n",
    "当运行该文件时，通过参数解析器传入必要参数，开始训练，并打印进程和设备id，以及训练总时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505f3e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 记录开始时间并启动训练\n",
    "    start_time = time.time()\n",
    "    train()\n",
    "    print(f\"total time: {(time.time() - start_time):.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c05f793-0a22-4a2f-9478-125a541dc862",
   "metadata": {},
   "source": [
    "## 评估阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29ab6dc-a96d-4e01-a914-49b4c5ab444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "from scipy.io import savemat, loadmat\n",
    "\n",
    "from mindspore import nn, ops, load_checkpoint, load_param_into_net, set_seed\n",
    "from mindflow.utils import load_yaml_config\n",
    "\n",
    "from src import my_test_dataset, AEnet, save_loss_curve\n",
    "\n",
    "np.random.seed(0)\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f856de1-6fa3-4a8f-a37d-c16cabcae4c7",
   "metadata": {},
   "source": [
    "## 读取并设置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4dc8fe-4359-4b08-a644-bf02845e6955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析命令行参数\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--mode\", type=str, default=\"GRAPH\")           # 运行模式：GRAPH/其他\n",
    "parser.add_argument(\"--device_target\", type=str, default=\"Ascend\")# 设备目标：Ascend/GPU/CPU\n",
    "parser.add_argument(\"--device_id\", type=int, default=0)              # 设备 ID\n",
    "parser.add_argument(\"--config_file_path\", type=str, default=\"./config.yaml\")  # 配置文件路径\n",
    "parser.add_argument(\"--infer_mode\", type=str, default=\"one\")       # 推理模式：one 或 cycle\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "# 加载配置文件，准备参数\n",
    "config = load_yaml_config(args.config_file_path)  # 从 YAML 配置文件中读取所有设置\n",
    "data_params = config[\"data\"]                      # 数据相关参数字典\n",
    "model_params = config[\"model\"]                    # 模型相关参数字典\n",
    "prediction_params = config[\"prediction\"]          # 推理相关参数字典\n",
    "prediction_result_dir = prediction_params[\"prediction_result_dir\"]  # 保存一次性预测结果的目录\n",
    "pred_continue_dir = prediction_params[\"pred_continue_dir\"]          # 保存循环预测结果的目录"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7422b62a-c891-48b3-b82f-02bb7a465ac1",
   "metadata": {},
   "source": [
    "## 构建网络模型并读取模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5630a2c3-1ccd-4310-b58b-30c2bec5dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 构建网络模型\n",
    "    net = AEnet(\n",
    "        in_channels=model_params[\"in_channels\"],          # 输入通道数\n",
    "        num_layers=model_params[\"num_layers\"],            # 网络层数\n",
    "        kernel_size=model_params[\"kernel_size\"],          # 卷积核大小\n",
    "        num_convlstm_layers=model_params[\"num_convlstm_layers\"]  # ConvLSTM 层数\n",
    "    )\n",
    "    # 加载模型参数\n",
    "    m_state_dict = load_checkpoint(prediction_params[\"ckpt_path\"])  # 从指定路径加载 checkpoint\n",
    "    load_param_into_net(net, m_state_dict)  # 将参数加载到网络中"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d071cf96-7fc6-4362-a91f-713dc613d43d",
   "metadata": {},
   "source": [
    "## 准备测试数据集并定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80599be5-95cb-4e4d-a00a-e25ed8937358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备测试数据集\n",
    "data_set = my_test_dataset(prediction_params[\"data_dir\"], data_params[\"time_steps\"])  # 创建测试数据迭代器\n",
    "# 若保存结果的目录不存在，则创建\n",
    "if not os.path.exists(prediction_result_dir):\n",
    "    os.mkdir(prediction_result_dir)\n",
    "if not os.path.exists(pred_continue_dir):\n",
    "    os.mkdir(pred_continue_dir)\n",
    "\n",
    "# 定义损失函数：均方误差 MSE\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "# 保存各步的测试损失\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643ada84-1599-4960-a46b-1efee195cbaa",
   "metadata": {},
   "source": [
    "## 根据参数设置选择预测的模式：单步预测或者循环预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c88cf-9983-4bde-b39f-09092c4a8266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据推理模式执行不同流程\n",
    "# 单步预测模式：predict next one-step flow field\n",
    "if args.infer_mode == \"one\":\n",
    "    for i, (input_1, velocity, label, matrix_01) in enumerate(data_set):\n",
    "        pred = net(input_1, velocity)                   # 前向推理，获取预测\n",
    "        pred = ops.mul(pred, matrix_01)                  # 对预测结果应用掩码或变换矩阵\n",
    "        loss = ops.sqrt(loss_func(pred, label))          # 计算预测值与真实值的均方根误差\n",
    "        test_losses.append(loss)                         # 记录损失张量\n",
    "        print(f\"test loss: {(loss.asnumpy().item()):.6f}\")  # 打印当前损失\n",
    "        # 保存预测结果与真实值到 mat 文件\n",
    "        savemat(f\"{prediction_result_dir}/prediction_data{i}.mat\", {\n",
    "            'prediction': pred.asnumpy(),\n",
    "            'real': label.asnumpy(),\n",
    "        })\n",
    "\n",
    "# 循环预测模式：predict a complete periodic flow field\n",
    "elif args.infer_mode == \"cycle\":\n",
    "    for i, (inputvar, velocityvar, targetvar, matrix_01) in enumerate(data_set):\n",
    "        if i == 0:\n",
    "            inputs = inputvar  # 第一帧输入\n",
    "        label = targetvar      # 真值\n",
    "        velocity = velocityvar # 流场速度\n",
    "        # 前向推理\n",
    "        pred = net(inputs, velocity)\n",
    "        pred = ops.mul(pred, matrix_01)                   # 应用矩阵变换\n",
    "        loss = ops.sqrt(loss_func(pred, label))           # 计算均方根误差\n",
    "        loss_aver = loss.asnumpy().item()                  # 转为 Python 数值\n",
    "\n",
    "        # 记录并打印损失\n",
    "        test_losses.append(loss_aver)\n",
    "        print(f\"test loss: {loss_aver:.6f}\")\n",
    "        # 保存循环预测结果\n",
    "        savemat(f\"{pred_continue_dir}/prediction_data{i}.mat\", {\n",
    "            'prediction': pred.asnumpy(),\n",
    "            'real': label.asnumpy(),\n",
    "        })\n",
    "        # 将当前预测结果拼接为下一步的输入\n",
    "        pred = ops.operations.ExpandDims()(pred, 1)       # 扩展维度以匹配输入格式\n",
    "        cat = ops.concat((inputs, pred), axis=1)          # 在时间维度上连接张量\n",
    "        inputs = cat[:, 1:, :, :, :]                     # 去掉最老的一帧，保留最新序列\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a63d3c6-6d58-4033-ab95-ef0569ba3007",
   "metadata": {},
   "source": [
    "## 绘制并保存测试损失曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31708ae-32c5-48fc-909c-325916f10695",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_loss_curve(\n",
    "        test_losses,        # 损失列表\n",
    "        'Epoch',            # 横轴标签\n",
    "        'test_losses',      # 纵轴标签\n",
    "        'Test_losses Curve',# 图表标题\n",
    "        'Test_losses.png'   # 输出文件名\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aac646",
   "metadata": {},
   "source": [
    "## 预测流场结果可视化\n",
    "\n",
    "+ 动边界流场预测通过执行eval.py开始预测，分为两种预测方式：单步流场预测（infer_mode为\"one\"）和一个振动周期内连续流场预测（infer_mode为\"cycle\"）；单步流场预测仅预测下一时刻一个时间步长的流场，连续流场预测则持续预测一个完整周期的流场\n",
    "+ 下图为在振幅比为0.25、0.30、0.35、0.40数据集上训练完备的HDNN模型，在0.45数据集上进行测试得到的结果\n",
    "+ 具体可以将eval.py处理得到的数据经过draw.py处理，得到dat文件，再使用Tecplot 360软件进行最后的可视化操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d229664b",
   "metadata": {},
   "source": [
    "![pred_single_step_puv.png](./images/pred_single_step_puv.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
